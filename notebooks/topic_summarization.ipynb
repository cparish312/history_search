{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring summarization of browser history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import html\n",
    "import shutil\n",
    "import requests\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import utils\n",
    "from chromadb_tools import get_chroma_collection, run_chroma_ingest, chroma_search_results_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_pages_dir = \"../data/history_pages/\"\n",
    "found_text = set()\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    texts = list()\n",
    "    for t in visible_texts:\n",
    "        t = t.strip()\n",
    "        if t not in found_text and len(t) > 10:\n",
    "            texts.append(t)\n",
    "        found_text.add(t)\n",
    "    return u\" \".join(texts).strip()\n",
    "\n",
    "def get_html(row):\n",
    "    html_path = os.path.join(history_pages_dir, f\"{row['url_hash']}.html\")\n",
    "    if os.path.exists(html_path):\n",
    "        with open(html_path, 'r') as infile:\n",
    "            return infile.read()\n",
    "        \n",
    "    try:\n",
    "        response = requests.get(row['url'])\n",
    "    except:\n",
    "        print(f\"Failed request for {row['url']}\")\n",
    "        return \"\"\n",
    "    with open(html_path, 'w') as outfile:\n",
    "        outfile.write(response.text)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10504 urls from Firefox\n",
      "73 urls from Chrome\n",
      "16 urls from Arc\n"
     ]
    }
   ],
   "source": [
    "chroma_collection = get_chroma_collection(collection_name=\"browser_history\")\n",
    "history = utils.get_browser_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"agentic rag\"\n",
    "top_n = 100\n",
    "\n",
    "chroma_search_results = chroma_collection.query(\n",
    "            query_texts=[text],\n",
    "            n_results=top_n\n",
    "    )\n",
    "results_df = chroma_search_results_to_df(chroma_search_results=chroma_search_results)\n",
    "results_df = results_df.loc[results_df['distance'] <= 1.2]\n",
    "\n",
    "results_history = history.loc[history['url'].isin(results_df['url'])]\n",
    "len(results_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/2c9vmfhd35bgwc_6h0q80d180000gn/T/ipykernel_63161/3198180405.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_history['html'] = results_history.apply(lambda row: get_html(row), axis=1)\n",
      "/var/folders/c_/2c9vmfhd35bgwc_6h0q80d180000gn/T/ipykernel_63161/1207840994.py:13: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  texts = soup.findAll(text=True)\n",
      "/var/folders/c_/2c9vmfhd35bgwc_6h0q80d180000gn/T/ipykernel_63161/3198180405.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_history['html_text'] = results_history['html'].apply(lambda x: text_from_html(x))\n"
     ]
    }
   ],
   "source": [
    "results_history['html'] = results_history.apply(lambda row: get_html(row), axis=1)\n",
    "results_history['html_text'] = results_history['html'].apply(lambda x: text_from_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_history = results_history.drop_duplicates(subset=['html_text'])\n",
    "results_history = results_history.loc[results_history['html_text'].str.len() > 10]\n",
    "len(results_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../data/test_dir'\n",
    "results_history['html_f'] = results_history['url_hash'].apply(lambda x :os.path.join(history_pages_dir, f\"{x}.html\"))\n",
    "results_history['html_f_test'] = results_history['url_hash'].apply(lambda x :os.path.join(test_dir, f\"{x}.html\"))\n",
    "for i, row in results_history.iterrows():\n",
    "    if os.path.exists(row['html_f']):\n",
    "        shutil.copy(row['html_f'], row['html_f_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_text(row):\n",
    "    return f\"\"\"Access time: {row['datetime_local']}\\n\n",
    "    Web Page text: {row['html_text']}\\n\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = text\n",
    "pre_prompt = f\"\"\"Below are webpages a user has been looking at related to the topic of {topic} \n",
    "    along with the timestamp the webpage was accessed. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_history = results_history.sort_values(by='datetime_local', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_history['thumbnail_url'] = results_history.apply(lambda row: utils.get_thumbnail_url(row['url'], row['html']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try summarizing using Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connorparish/miniconda3/envs/hindsight_exp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "\n",
    "MLX_LLM_MODEL = \"mlx-community/Meta-Llama-3.1-8B-Instruct-8bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load(MLX_LLM_MODEL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarize_prompt(html_text):\n",
    "    # prompt = f\"\"\"Below is text from a webpage.\\n {html_text}\\n \n",
    "    # Extract the key points from the webpage in relation to {topic}. Key Points:\\n\"\"\"\n",
    "    prompt = f\"\"\"Below is text from a webpage.\\n {html_text}\\n \n",
    "        Create a short bullet-point TLDR summary in relation to {topic}. Only use the \n",
    "        text provided. Summary:\\n\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_history['summary'] = results_history['html_text'].apply(lambda x: generate(model, tokenizer, prompt=get_summarize_prompt(x), max_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-13\n",
      "2024-08-06\n",
      "2024-08-05\n",
      "2024-08-03\n",
      "2024-08-02\n",
      "2024-07-30\n",
      "2024-07-02\n",
      "2024-05-01\n"
     ]
    }
   ],
   "source": [
    "def get_summary_html(row):\n",
    "    # Check for thumbnail and adjust HTML accordingly\n",
    "    thumbnail_html = \"\"\n",
    "    if row['thumbnail_url']:\n",
    "        thumbnail_html = f\"\"\"\n",
    "            <div class=\"thumbnail-container\">\n",
    "                <a href=\"{row['url']}\" target=\"_blank\">\n",
    "                    <img src=\"{row['thumbnail_url']}\" alt=\"Thumbnail for {row['title']}\" class=\"content-thumbnail\">\n",
    "                </a>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "\n",
    "    # Escape HTML special characters in the summary and convert newlines to HTML breaks\n",
    "    escaped_summary = html.escape(row['summary']).replace('\\n', '<br>')\n",
    "\n",
    "    # Combine all parts\n",
    "    html_content = f\"\"\"\n",
    "        <div class=\"content-container\" data-content-id=\"{row['id']}\">\n",
    "            {thumbnail_html}\n",
    "            <div class=\"text-container\">\n",
    "                <a href=\"{row['url']}\" target=\"_blank\" onclick=\"trackClick({row['id']});\" class=\"content-title\">{row['title']}</a>\n",
    "                <div class=\"summary\">{escaped_summary}</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    return html_content\n",
    "\n",
    "def generate_full_html(results_history, topic):\n",
    "    styles = '''\n",
    "    <style>\n",
    "        .content-container {\n",
    "            display: flex; /* Flexbox layout to align image and text side by side */\n",
    "            border-bottom: 1px solid #ccc; /* Adds a border between entries */\n",
    "            padding-bottom: 10px; /* Spacing below each item */\n",
    "            margin-bottom: 10px; /* Spacing between items */\n",
    "        }\n",
    "        .thumbnail-container {\n",
    "            flex: 0 0 auto; /* Flex item does not grow or shrink */\n",
    "            margin-right: 10px; /* Space between the image and the text */\n",
    "        }\n",
    "        .text-container {\n",
    "            flex: 1; /* Allows the text container to take up remaining space */\n",
    "        }\n",
    "        .content-thumbnail {\n",
    "            width: 100px; /* Sets a fixed width */\n",
    "            height: 100px; /* Sets a fixed height */\n",
    "            object-fit: contain; /* Ensures the image fits within dimensions without cropping */\n",
    "        }\n",
    "        .summary {\n",
    "            white-space: pre-wrap; /* Maintains whitespace formatting */\n",
    "        }\n",
    "        .date-header {\n",
    "            font-size: 18px; /* Size of date header */\n",
    "            font-weight: bold; /* Make date header bold */\n",
    "            margin-top: 20px; /* Top margin for spacing */\n",
    "            margin-bottom: 10px; /* Bottom margin before content starts */\n",
    "        }\n",
    "        .header {\n",
    "            font-size: 24px; /* Larger font size for header */\n",
    "            text-align: center; /* Center-align the header text */\n",
    "            margin: 20px 0; /* Top and bottom margin for spacing */\n",
    "        }\n",
    "    </style>\n",
    "    '''\n",
    "    header_html = f'<div class=\"header\">Topic: {topic}</div>'\n",
    "\n",
    "    summaries_html = styles + header_html\n",
    "    \n",
    "    results_history = results_history.sort_values('datetime_local', ascending=False)\n",
    "    results_history['day_accessed'] = results_history['datetime_local'].dt.date\n",
    "\n",
    "    for date in results_history.day_accessed.unique():\n",
    "        date_df = results_history.loc[results_history['day_accessed'] == date]\n",
    "        summaries_html += f'<div class=\"date-header\">Accessed on: {date}</div>'\n",
    "        for i, row in date_df.iterrows():\n",
    "            summaries_html += get_summary_html(row)\n",
    "\n",
    "    return summaries_html\n",
    "\n",
    "html_output = generate_full_html(results_history, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/output_summaries/\"\n",
    "with open(os.path.join(output_dir, \"agentic_rag_summary.html\"), 'w') as outfile:\n",
    "    outfile.write(html_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create summary of summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_text(row):\n",
    "    return f\"\"\"Access time: {row['datetime_local']}\\n\n",
    "    Web Page summary: {row['summary']}\\n\n",
    "    \"\"\"\n",
    "\n",
    "def get_summaries_summary_prompt(df):\n",
    "    prompt = f\"Below are summaries extracted from different webpages related to the topic {topic}. \\n\"\n",
    "    for i, row in df.iterrows():\n",
    "        prompt += get_url_text(row)\n",
    "    prompt += \"Create a summary of the below summaries focusing on {topic}. Answer: \\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = get_summaries_summary_prompt(results_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_summary = generate(model, tokenizer, prompt=summary_prompt, max_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic RAG is a transformative approach to Retrieval-Augmented Generation (RAG) technology, integrating agentic capabilities to create intelligent systems that reason over retrieved information, execute multi-step actions, and synthesize insights from diverse sources. This adaptive approach empowers users to conduct comprehensive research and achieve unparalleled efficiency. Agentic RAG has the potential to revolutionize information retrieval and analysis, blurring the boundaries between human and machine intelligence. The technology holds profound promise for the future of information retrieval and analysis, with applications in various fields, including research, education, and business. Agentic RAG is a game-changer in the field of information retrieval, offering a more efficient and effective way to access and analyze information. The technology has the potential to transform the way we interact with information, making it more accessible and user-friendly. Agentic RAG is a powerful tool for researchers, educators, and professionals who need to analyze and understand complex information. It can help them to identify patterns, relationships,\n"
     ]
    }
   ],
   "source": [
    "print(summary_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hindsight_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
